{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "### ESI4628: Decision Support Systems for Industrial Engineers\n",
    "University of Central Florida\n",
    "\n",
    "Fall 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### According to UCF Golden rules of academic ethics and honesty, plagiarism is not acceptable under any circumstances.\n",
    "\n",
    "#### Student Name: \n",
    "\n",
    "## NOTE:\n",
    "+ Pay attention to instructions, no second chance provided under any grounds.\n",
    "+ Unclear/incomplete/deficient answers will impact the final grade.\n",
    "+ Late submissions or wrong templates will not be entertained, may that be wrong file upload or incomplete/unexecuted markdown cells or whatever.\n",
    "+ Solutions files are expected to be the same format as this file. \n",
    "+ Students are expected to answer all the questions.\n",
    "+ Plagiarised answers shall receive zero points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For __Question 1-4__, We will load _1000_Companies.csv_ dataset that contains data belongs to 1000 companies such as R&D, administration and marketing spendings and location. We will use this data to build a machine learning based decision suppport system model to predict companies' profit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: 10  Points (Load Data)\n",
    "\n",
    "- (A) Load the \"1000_Companies.csv\" dataset - 5 points\n",
    "- (B) Display the first and last 5 rows of this dataset  - 5 points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8064/2536197922.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#- (A) Load the \"1000_Companies.csv\" dataset - 5 points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "#- (A) Load the \"1000_Companies.csv\" dataset - 5 points\n",
    "df = pd.read_csv(r'C:\\Users\\jguasp\\Downloads\\1000_Companies.csv')\n",
    "#-(B) Display the first and last 5 rows of this dataset  - 5 points\n",
    "print(df.head(5))\n",
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: 15  Points (Manipulate Data)\n",
    "                                                           \n",
    "- (A) Extract the independent (Feature Matrix) and dependent (target vector) variables.  - 5 points\n",
    "- (B) Encode the categorical data following the following steps:\n",
    "\n",
    "    _1)_ Integer Encoding - 5 points\n",
    "    \n",
    "    _2)_  One-Hot Encoding - 5 points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(A)Extract the independent (Feature Matrix) and dependent (target vector) variables.\n",
    "X = df.iloc[:,0:4]\n",
    "y = df.iloc[:,4]\n",
    "\n",
    "#(B)Encode the categorical data following the following steps\n",
    "##1)Integer Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(np.array(X['State']))\n",
    "label = encoder.transform(X['State'])\n",
    "states = np.array(X['State'])\n",
    "label.ndim\n",
    "states.ndim\n",
    "label = label[np.newaxis]\n",
    "states = states[np.newaxis]\n",
    "states = np.append(states, label, axis = 0)\n",
    "states = states.T\n",
    "print(cat.head())\n",
    "cat_array = cat.values\n",
    "print(X.head())\n",
    "##2) One-Hot Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = df.iloc[:,0:4]\n",
    "\n",
    "X['State'] = X.State.replace({'California':0,'Florida':1,'New York':2})\n",
    "dummies = pd.get_dummies(X.State, prefix='State')\n",
    "X = pd.concat([X, dummies], axis=1)\n",
    "X = X.drop(columns='State')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: 35  Points (Modeling)\n",
    "\n",
    "- (A) Split the dataset into the training and test sets. Hint: Use train_test_split(test_size=0.3, shuffle = False)  - 5 points\n",
    "- (B) Use Linear Regression Modeling to train your model (Name your model as Model1_LRM) - 5 points\n",
    "- (C) Use the trained model (Model1_LRM) and the test dataset for prediction - 5 points\n",
    "- (D) Calculate the accuracy of your Model1_LRM model. Hint: Use r2_score from sklearn.metrics - 5 points\n",
    "- (E) Use Random Forest Regressor Modeling to train your model (Name your model Model2_RFR)  - 5 points\n",
    "- (F) Use the trained model(Model2_RFR) and the test dataset for prediction - 5 points\n",
    "- (G) Calculate the accuracy of your Model2_RFR model. Hint: Use r2_score from sklearn.metrics - 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8064/2916251371.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#(A) Split the dataset into the training and test sets. Hint: Use train_test_split(test_size=0.3, shuffle = False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#(B) Use Linear Regression Modeling to train your model (Name your model as Model1_LRM)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#(A) Split the dataset into the training and test sets. Hint: Use train_test_split(test_size=0.3, shuffle = False)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=0, shuffle = False) \n",
    "#(B) Use Linear Regression Modeling to train your model (Name your model as Model1_LRM)\n",
    "Model1_LRM = sk.linear_model.LinearRegression()\n",
    "Model1_LRM.fit(X_train, y_train)\n",
    "#(C) Use the trained model (Model1_LRM) and the test dataset for prediction\n",
    "pred_LRM = pd.DataFrame(Model1_LRM.predict(X_test))\n",
    "#(D) Calculate the accuracy of your Model1_LRM model. Hint: Use r2_score from sklearn.metrics\n",
    "print(\"R2 Score Linear Regression:\", sk.metrics.r2_score(y_test, pred_LRM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.724613670616963"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(E) Use Random Forest Regressor Modeling to train your model (Name your model Model2_RFR)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "Model2_RFR = sk.ensemble.RandomForestRegressor()\n",
    "Model2_RFR.fit(X_train, y_train)\n",
    "#(F) Use the trained model(Model2_RFR) and the test dataset for prediction\n",
    "pred_RFR = pd.DataFrame(Model2_RFR.predict(X_test))\n",
    "#(G) Calculate the accuracy of your Model2_RFR model. Hint: Use r2_score from sklearn.metrics\n",
    "print(\"R2 Score Random Forest:\", sk.metrics.r2_score(y_test, pred_RFR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: 15  Points (Visualization)\n",
    "\n",
    "- (A) Graph the difference between predicted and actual (test) values for both models( Model1_LRM and Model2_RFR) and the actual (test) values.  - 5 points\n",
    "- (B) Label your x-axis 'Companies', y-axis as 'Profit', and 'Model Comparison' as title and legend (Model1_LRM','Model2_RFM','ActualProfit')  - 5 points\n",
    "- (C) Write a conclusion based on the comparison of these two models  - 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8064/2196200537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#(A) Graph the difference between predicted and actual (test) values for both models( Model1_LRM and Model2_RFR) and the actual (test) values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#ax.plot([0, 1], [0, 1], ls=\"--\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "#(A) Graph the difference between predicted and actual (test) values for both models( Model1_LRM and Model2_RFR) and the actual (test) values.\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "#ax.plot([0, 1], [0, 1], ls=\"--\") \n",
    "ax.set_xlabel('Companies')\n",
    "ax.set_ylabel('Profit')\n",
    "ax.set_title('Model Comparison')\n",
    "ActualProfit = pd.DataFrame(np.array(y_test))\n",
    "\n",
    "ax.set_xlim([0.0, 300])\n",
    "ax.set_ylim([0.0, 500000]) \n",
    "\n",
    "ax.plot(pred_LRM, label = 'Model1_LRM', marker ='o')\n",
    "ax.plot(pred_RFR, label = 'Model2_RFR', marker = 'o')\n",
    "ax.plot(ActualProfit, label = 'ActualProfit')\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#(B) Label your x-axis 'Companies', y-axis as 'Profit', and 'Model Comparison' as title and legend (Model1_LRM','Model2_RFM','ActualProfit')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#(C) Write a conclusion based on the comparison of these two models\n",
    "#### Conclusion:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off of the graph of the comparison of the two models, both the Random Forest and Linear Regression models do an adequate job of predicting company profit. Almost all data points lie on the same points. This is also shown in the R2 score of each model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5: 25  Points\n",
    "\n",
    "Load the \"titanic\" dataset from the Seaborn library as described in class (see DSS-Unit05-Lecture02.2020.ipynb). Using this data answer the following questions:\n",
    "- (A) Display the first rows of these dataset  - 5 points\n",
    "- (B) How many passengers from First, Second and Third class survived? (hint: group by class)  - 5 points\n",
    "- (C) What percentage of First class pasengers that embarked from Southampton survived? For the same group (First class that embarked in Southampton) what was their average age? how much did they pay for their fare in average? (hint: group by, get group and mean)  - 5 points\n",
    "- (D) Calculate the average age and the average fare paid for each of the following: passengers in First, Second and Third class that survived and that not survived. Please display these results in a table (dataframe). (hint: use pivot tables).  - 5 points\n",
    "- (E) What is the percentage of female passengers traveling in first class that survived? What was their average age?  - 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(A) Display the first rows of these dataset\n",
    "import seaborn as sb\n",
    "\n",
    "titanic = sb.load_dataset('titanic')\n",
    "print(titanic.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(B) How many pasengers from First, Second and Third class survived?\n",
    "#Grouping by sex using the mean to aggregate\n",
    "First = titanic[titanic.pclass == 1]\n",
    "print(\"First Class Surviors:\", First['survived'].sum(axis = 0))\n",
    "Second = titanic[titanic.pclass == 2]\n",
    "print(\"Second Class Survivors:\", Second['survived'].sum(axis = 0))\n",
    "Third = titanic[titanic.pclass == 3]\n",
    "print(\"Third Class Survivors:\", Third['survived'].sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(C) What percentage of First class pasengers that embarked from Southampton survived? \n",
    "Southampton = titanic[titanic.embark_town == 'Southampton']\n",
    "print(\"Passengers Survived from Southampton:\", Southampton['survived'].sum(axis=0))\n",
    "#For the same group (First class that embarked in Southampton) what was their average age? \n",
    "print(\"Southampton Average Age:\", Southampton['age'].mean(axis=0))\n",
    "#how much did they pay for their fare in average? (hint: group by, get group and mean) \n",
    "print(\"Southampton Average Ticket Price:\", Southampton['fare'].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(D) Calculate the average age and the average fare paid for each of the following: \n",
    "#passengers in First, Second and Third class that survived and that not survived.\n",
    "First_S = First[First.survived == 1]\n",
    "print(\"Average Age First Class (Survived):\", First_S['age'].mean(axis=0))\n",
    "print(\"Average Fare First Class (Survived):\", First_S['fare'].mean(axis=0))\n",
    "First_NS = First[First.survived == 0]\n",
    "print(\"Average Age First Class (Not Survived):\", First_NS['age'].mean(axis=0))\n",
    "print(\"Average Fare First Class (Not Survived):\", First_NS['fare'].mean(axis=0))\n",
    "\n",
    "Second_S = Second[Second.survived == 1]\n",
    "print(\"Average Age Second Class (Survived):\", Second_S['age'].mean(axis=0))\n",
    "print(\"Average Fare Second Class (Survived):\", Second_S['fare'].mean(axis=0))\n",
    "Second_NS = Second[Second.survived == 0]\n",
    "print(\"Average Age Second Class (Not Survived):\", Second_NS['age'].mean(axis=0))\n",
    "print(\"Average Fare Second Class (Not Survived):\", Second_NS['fare'].mean(axis=0))\n",
    "\n",
    "Third_S = Third[Third.survived == 1]\n",
    "print(\"Average Age Third Class (Survived):\", Third_S['age'].mean(axis=0))\n",
    "print(\"Average Fare Third Class (Survived):\", Third_S['fare'].mean(axis=0))\n",
    "Third_NS = Third[Third.survived == 0]\n",
    "print(\"Average Age Third Class (Not Survived):\", Third_NS['age'].mean(axis=0))\n",
    "print(\"Average Fare Third Class (Not Survived):\", Third_NS['fare'].mean(axis=0))\n",
    "#Please display these results in a table (dataframe). (hint: use pivot tables).\n",
    "titanic_pivot = titanic.pivot_table(index = ['survived','class'], values = ['age', 'fare'], aggfunc ='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(E) What is the percentage of female passengers traveling in Third class that survived? \n",
    "#What was their average age?\n",
    "Third_F = Third[Third.sex == 'female']\n",
    "print(\"Percentage of Survival - Third Class Females: \", 100*(Third_F['survived'].sum(axis=0))/len(Third_F))\n",
    "print(\"Age of Survived - Third Class Females:\", Third_F['age'].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f15e19d9648079257051de984edd5fb8186b42c5b062c4b5610c6e8342fa85a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
